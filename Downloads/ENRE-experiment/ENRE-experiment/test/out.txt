output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output;30
udb_path;64
udb_path;64
lang;64
language;64
project;64
project_root;64
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root);47
shell;47
True;47
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True);30
output;47
logging.info(output);30
subprocess.CalledProcessError;23
e.output;47
logging.exception(e.output);30
"udb creation failed";47
logging.fatal("udb creation failed");30
Exception;28
defs;26
";";43
defline.split(";");26
defs;39
len(defs);22
0;22
token;29
defs;30
1;48
defs[:-1];30
definition;18
defs;23
tmps;30
"->";47
definition.split("->");30
var;30
0;47
tmps[0];30
replace_label;30
1;47
tmps[1];30
token;26
var;26
"var";33
token;25
dataPath;22
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\";22
defPath;22
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\";22
gitRoot;22
"J:\\git_repo\\";22
cpRoot;22
"J:\\Vulnerability_commit\\";22
files;22
dataPath;39
os.listdir(dataPath);22
def_files;22
defPath;39
os.listdir(defPath);22
txtFile;14
files;19
txtName;26
".";43
0;43
txtFile.split(".")[0];26
srcName;26
txtName;26
"_src.txt";26
srcName1;26
txtName;26
"_token_src.txt";26
dstName;26
txtName;26
"_dst.txt";26
dstName1;26
txtName;26
"_token_dst.txt";26
src_defPath;26
defPath;26
txtName;26
"_defs_src.txt";26
dst_defPath;26
defPath;26
txtName;26
"_defs_dst.txt";26
txt;26
dataPath;43
txtFile;43
"r";43
open(dataPath + txtFile, "r");26
txt_srcDef;26
src_defPath;43
"r";43
open(src_defPath, "r");26
txt_dstDef;26
src_defPath;43
"r";43
open(src_defPath, "r");26
lines;26
txt.readlines();26
lines_srcDef;26
txt_srcDef.readlines();26
lines_dstDef;26
txt_dstDef.readlines();26
repoName;26
"_";43
0;43
txtFile.split("_")[0];26
cpName;26
"_";43
1;43
".";43
0;43
txtFile.split("_")[1].split(".")[0];26
gitPath;26
gitRoot;26
repoName;26
"\\";26
diffPath;26
cpRoot;26
cpName;26
"\\diffs.txt";26
diffFile;26
diffPath;43
"r";43
open(diffPath, "r");26
diffLines;26
diffFile.readlines();26
old_commit;26
1;43
";";43
0;43
diffLines[1].split(";")[0];26
new_commit;26
1;43
";";43
1;43
diffLines[1].split(";")[1];26
gitPath;43
os.chdir(gitPath);26
fileName;26
"";26
startLine_src;26
0;26
endLine_src;26
0;26
startCol_src;26
0;26
endCol_src;26
0;26
startLine_dst;26
0;26
endLine_dst;26
0;26
startCol_dst;26
0;26
endCol_dst;26
0;26
lines;39
len(lines);22
0;22
src;30
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\";47
srcName;47
"w";47
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w");30
dst;30
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\";47
dstName;47
"w";47
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w");30
"git checkout ";47
old_commit;47
os.system("git checkout " + old_commit);30
old_path;30
"J:\\test\\old.udb";30
db;30
old_path;47
understand.open(old_path);30
lineNum;30
0;30
line;22
lines;27
defLine_src;34
lineNum;51
lines_srcDef[lineNum];34
longName_src;34
";";51
0;51
line.split(";")[0];34
"longName:";51
longName_src;51
print("longName:", longName_src);34
tmps;34
"\\";51
longName_src.split("\\");34
fileName;34
tmps;68
len(tmps);51
1;51
tmps[len(tmps) - 1];34
exact_longName;34
"";34
begin_index;34
"src";51
tmps.index("src");34
tmps;34
begin_index;51
tmps;68
len(tmps);51
tmps[begin_index:len(tmps)];34
tmp;26
tmps;31
exact_longName;37
tmp;37
"\\";37
exact_longName;34
1;52
exact_longName[:-1];34
"exactName:";51
exact_longName;51
print("exactName:", exact_longName);34
startLine_src;34
";";68
2;68
"->";68
0;68
",";68
0;68
line.split(";")[2].split("->")[0].split(",")[0];51
int(line.split(";")[2].split("->")[0].split(",")[0]);34
endLine_src;34
";";68
2;68
"->";68
0;68
",";68
1;68
line.split(";")[2].split("->")[0].split(",")[1];51
int(line.split(";")[2].split("->")[0].split(",")[1]);34
startCol_src;34
";";68
2;68
"->";68
0;68
",";68
2;68
line.split(";")[2].split("->")[0].split(",")[2];51
int(line.split(";")[2].split("->")[0].split(",")[2]);34
endCol_src;34
";";68
2;68
"->";68
0;68
",";68
3;68
line.split(";")[2].split("->")[0].split(",")[3];51
int(line.split(";")[2].split("->")[0].split(",")[3]);34
findFile;34
False;34
begin;34
False;34
startLine_src;51
endLine_src;51
startCol_src;51
endCol_src;51
print(startLine_src, endLine_src, startCol_src, endCol_src);34
file;26
"File";48
db.ents("File");31
exact_longName;34
file.longname();34
"find file:";59
fileName;59
file.longname();59
print("find file:", fileName, file.longname());42
lexemes;42
startLine_src;59
endLine_src;59
file.lexer().lexemes(startLine_src, endLine_src);42
start_lexeme;42
startLine_src;59
startCol_src;59
1;59
file.lexer().lexeme(startLine_src, startCol_src-1);42
type_exist;42
True;42
start_lexeme;38
None;38
start_text;46
start_lexeme.text();46
start_token;46
start_lexeme.token();46
"start_text:";63
start_text;63
print("start_text:" + start_text);46
type_exist;46
False;46
"error type!";63
print("error type!");46
size;42
lexemes;59
len(lexemes);42
count;42
0;42
fullText;42
"";42
lexeme;34
lexemes;39
count;45
1;45
type_exist;42
True;42
lexeme.text();62
start_text;62
lexeme.token();62
start_token;62
(lexeme.text() != start_text or lexeme.token() != start_token);46
begin;46
False;46
lexeme.text();46
start_text;46
lexeme.token();46
start_token;46
begin;54
True;54
lexeme.token();42
"Comment";42
lexeme.token();42
"Whitespace";42
lexeme.token();42
"Newline";42
text;46
lexeme.text();63
str(lexeme.text());46
lexeme.token();42
"Literal";42
text;50
"num";50
lexeme.token();42
"String";42
text;50
"\"\"";50
text;46
text;63
defLine_src;63
normalization(text, defLine_src);46
text;46
text;46
" ";46
count;42
size;42
1;42
text;50
"}";67
"";67
text.replace("}", "");50
text;50
"{";67
"";67
text.replace("{", "");50
text;50
";";67
"";67
text.replace(";", "");50
fullText;45
text;45
text;63
end;63
"";63
print(text, end="");46
findFile;42
True;42
fullText;59
src.write(fullText);42
lineNum;33
1;33
"\r\n-----------";51
print("\r\n-----------");34
"\n------\n";51
src.write("\n------\n");34
findFile;30
False;30
Exception;36
"git checkout ";47
new_commit;47
os.system("git checkout " + new_commit);30
new_path;30
"J:\\test\\new.udb";30
db;30
new_path;47
understand.open(new_path);30
lineNum;30
0;30
line;22
lines;27
defLine_dst;34
lineNum;51
lines_dstDef[lineNum];34
longName_dst;34
";";51
1;51
line.split(";")[1];34
"longName:";51
longName_dst;51
print("longName:", longName_dst);34
tmps;34
"\\";51
longName_dst.split("\\");34
fileName;34
tmps;68
len(tmps);51
1;51
tmps[len(tmps) - 1];34
exact_longName;34
"";34
begin_index;34
"src";51
tmps.index("src");34
tmps;34
begin_index;51
tmps;68
len(tmps);51
tmps[begin_index:len(tmps)];34
tmp;26
tmps;31
exact_longName;37
tmp;37
"\\";37
exact_longName;34
1;52
exact_longName[:-1];34
"exactName:";51
exact_longName;51
print("exactName:", exact_longName);34
startLine_dst;34
":";68
2;68
"->";68
1;68
",";68
0;68
line.split(":")[2].split("->")[1].split(",")[0];51
int(line.split(":")[2].split("->")[1].split(",")[0]);34
endLine_dst;34
":";68
2;68
"->";68
1;68
",";68
1;68
line.split(":")[2].split("->")[1].split(",")[1];51
int(line.split(":")[2].split("->")[1].split(",")[1]);34
startCol_dst;34
":";68
2;68
"->";68
1;68
",";68
2;68
line.split(":")[2].split("->")[1].split(",")[2];51
int(line.split(":")[2].split("->")[1].split(",")[2]);34
endCol_dst;34
":";68
2;68
"->";68
1;68
",";68
3;68
line.split(":")[2].split("->")[1].split(",")[3];51
int(line.split(":")[2].split("->")[1].split(",")[3]);34
findFile;34
False;34
begin;34
False;34
startLine_dst;51
endLine_dst;51
startCol_dst;51
endCol_dst;51
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst);34
file;26
"File";48
db.ents("File");31
exact_longName;34
file.longname();34
"find file:";59
fileName;59
file.longname();59
print("find file:", fileName, file.longname());42
lexemes;42
startLine_dst;59
endLine_dst;59
file.lexer().lexemes(startLine_dst, endLine_dst);42
start_lexeme;42
startLine_dst;59
startCol_dst;59
1;59
file.lexer().lexeme(startLine_dst, startCol_dst-1);42
type_exist;42
True;42
start_lexeme;38
None;38
start_text;46
start_lexeme.text();46
start_token;46
start_lexeme.token();46
"start_text:";63
start_text;63
print("start_text:"+start_text);46
type_exist;46
False;46
"error type";63
print("error type");46
size;42
lexemes;59
len(lexemes);42
fullText;42
"";42
count;42
0;42
lexeme;34
lexemes;39
count;45
1;45
type_exist;42
True;42
lexeme.text();62
start_text;62
lexeme.token();62
start_token;62
(lexeme.text() != start_text or lexeme.token() != start_token);46
begin;46
False;46
lexeme.text();46
start_text;46
lexeme.token();46
start_token;46
begin;54
True;54
lexeme.token();42
"Comment";42
lexeme.token();42
"Whitespace";42
lexeme.token();42
"Newline";42
text;46
lexeme.text();63
str(lexeme.text());46
lexeme.token();42
"Literal";42
text;50
"num";50
lexeme.token();42
"String";42
text;50
"\"\"";50
text;46
text;63
defLine_dst;63
normalization(text, defLine_dst);46
text;46
text;46
" ";46
count;42
size;42
1;42
text;50
"}";67
"";67
text.replace("}", "");50
text;50
"{";67
"";67
text.replace("{", "");50
text;50
";";67
"";67
text.replace(";", "");50
fullText;45
text;45
text;63
end;63
"";63
print(text, end="");46
findFile;42
True;42
fullText;59
dst.write(fullText);42
lineNum;33
1;33
"\r\n-----------";51
print("\r\n-----------");34
"\n------\n";51
dst.write("\n------\n");34
findFile;30
False;30
Exception;36
src.close();30
dst.close();30
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
output
udb_path
udb_path
lang
language
project
project_root
"und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root)
shell
True
subprocess.check_output            "und create -db {udb_path} -languages {lang} add {project} analyze".format(udb_path=udb_path, lang=language, project=project_root),            shell=True)
output
logging.info(output)
subprocess.CalledProcessError
e.output
logging.exception(e.output)
"udb creation failed"
logging.fatal("udb creation failed")
Exception
defs
";"
defline.split(";")
defs
len(defs)
0
token
defs
1
defs[:-1]
definition
defs
tmps
"->"
definition.split("->")
var
0
tmps[0]
replace_label
1
tmps[1]
token
var
"var"
token
dataPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_num1\\"
defPath
"D:\\workspace\\Pycharm\\Understand_analysis\\data_var1\\"
gitRoot
"J:\\git_repo\\"
cpRoot
"J:\\Vulnerability_commit\\"
files
dataPath
os.listdir(dataPath)
def_files
defPath
os.listdir(defPath)
txtFile
files
txtName
"."
0
txtFile.split(".")[0]
srcName
txtName
"_src.txt"
srcName1
txtName
"_token_src.txt"
dstName
txtName
"_dst.txt"
dstName1
txtName
"_token_dst.txt"
src_defPath
defPath
txtName
"_defs_src.txt"
dst_defPath
defPath
txtName
"_defs_dst.txt"
txt
dataPath
txtFile
"r"
open(dataPath + txtFile, "r")
txt_srcDef
src_defPath
"r"
open(src_defPath, "r")
txt_dstDef
src_defPath
"r"
open(src_defPath, "r")
lines
txt.readlines()
lines_srcDef
txt_srcDef.readlines()
lines_dstDef
txt_dstDef.readlines()
repoName
"_"
0
txtFile.split("_")[0]
cpName
"_"
1
"."
0
txtFile.split("_")[1].split(".")[0]
gitPath
gitRoot
repoName
"\\"
diffPath
cpRoot
cpName
"\\diffs.txt"
diffFile
diffPath
"r"
open(diffPath, "r")
diffLines
diffFile.readlines()
old_commit
1
";"
0
diffLines[1].split(";")[0]
new_commit
1
";"
1
diffLines[1].split(";")[1]
gitPath
os.chdir(gitPath)
fileName
""
startLine_src
0
endLine_src
0
startCol_src
0
endCol_src
0
startLine_dst
0
endLine_dst
0
startCol_dst
0
endCol_dst
0
lines
len(lines)
0
src
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
srcName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+srcName, "w")
dst
"D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"
dstName
"w"
open("D:\\workspace\\Pycharm\\Understand_analysis\\seqs\\"+dstName, "w")
"git checkout "
old_commit
os.system("git checkout " + old_commit)
old_path
"J:\\test\\old.udb"
db
old_path
understand.open(old_path)
lineNum
0
line
lines
defLine_src
lineNum
lines_srcDef[lineNum]
longName_src
";"
0
line.split(";")[0]
"longName:"
longName_src
print("longName:", longName_src)
tmps
"\\"
longName_src.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_src
";"
2
"->"
0
","
0
line.split(";")[2].split("->")[0].split(",")[0]
int(line.split(";")[2].split("->")[0].split(",")[0])
endLine_src
";"
2
"->"
0
","
1
line.split(";")[2].split("->")[0].split(",")[1]
int(line.split(";")[2].split("->")[0].split(",")[1])
startCol_src
";"
2
"->"
0
","
2
line.split(";")[2].split("->")[0].split(",")[2]
int(line.split(";")[2].split("->")[0].split(",")[2])
endCol_src
";"
2
"->"
0
","
3
line.split(";")[2].split("->")[0].split(",")[3]
int(line.split(";")[2].split("->")[0].split(",")[3])
findFile
False
begin
False
startLine_src
endLine_src
startCol_src
endCol_src
print(startLine_src, endLine_src, startCol_src, endCol_src)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_src
endLine_src
file.lexer().lexemes(startLine_src, endLine_src)
start_lexeme
startLine_src
startCol_src
1
file.lexer().lexeme(startLine_src, startCol_src-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:" + start_text)
type_exist
False
"error type!"
print("error type!")
size
lexemes
len(lexemes)
count
0
fullText
""
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_src
normalization(text, defLine_src)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
src.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
src.write("\n------\n")
findFile
False
Exception
"git checkout "
new_commit
os.system("git checkout " + new_commit)
new_path
"J:\\test\\new.udb"
db
new_path
understand.open(new_path)
lineNum
0
line
lines
defLine_dst
lineNum
lines_dstDef[lineNum]
longName_dst
";"
1
line.split(";")[1]
"longName:"
longName_dst
print("longName:", longName_dst)
tmps
"\\"
longName_dst.split("\\")
fileName
tmps
len(tmps)
1
tmps[len(tmps) - 1]
exact_longName
""
begin_index
"src"
tmps.index("src")
tmps
begin_index
tmps
len(tmps)
tmps[begin_index:len(tmps)]
tmp
tmps
exact_longName
tmp
"\\"
exact_longName
1
exact_longName[:-1]
"exactName:"
exact_longName
print("exactName:", exact_longName)
startLine_dst
":"
2
"->"
1
","
0
line.split(":")[2].split("->")[1].split(",")[0]
int(line.split(":")[2].split("->")[1].split(",")[0])
endLine_dst
":"
2
"->"
1
","
1
line.split(":")[2].split("->")[1].split(",")[1]
int(line.split(":")[2].split("->")[1].split(",")[1])
startCol_dst
":"
2
"->"
1
","
2
line.split(":")[2].split("->")[1].split(",")[2]
int(line.split(":")[2].split("->")[1].split(",")[2])
endCol_dst
":"
2
"->"
1
","
3
line.split(":")[2].split("->")[1].split(",")[3]
int(line.split(":")[2].split("->")[1].split(",")[3])
findFile
False
begin
False
startLine_dst
endLine_dst
startCol_dst
endCol_dst
print(startLine_dst, endLine_dst, startCol_dst, endCol_dst)
file
"File"
db.ents("File")
exact_longName
file.longname()
"find file:"
fileName
file.longname()
print("find file:", fileName, file.longname())
lexemes
startLine_dst
endLine_dst
file.lexer().lexemes(startLine_dst, endLine_dst)
start_lexeme
startLine_dst
startCol_dst
1
file.lexer().lexeme(startLine_dst, startCol_dst-1)
type_exist
True
start_lexeme
None
start_text
start_lexeme.text()
start_token
start_lexeme.token()
"start_text:"
start_text
print("start_text:"+start_text)
type_exist
False
"error type"
print("error type")
size
lexemes
len(lexemes)
fullText
""
count
0
lexeme
lexemes
count
1
type_exist
True
lexeme.text()
start_text
lexeme.token()
start_token
(lexeme.text() != start_text or lexeme.token() != start_token)
begin
False
lexeme.text()
start_text
lexeme.token()
start_token
begin
True
lexeme.token()
"Comment"
lexeme.token()
"Whitespace"
lexeme.token()
"Newline"
text
lexeme.text()
str(lexeme.text())
lexeme.token()
"Literal"
text
"num"
lexeme.token()
"String"
text
"\"\""
text
text
defLine_dst
normalization(text, defLine_dst)
text
text
" "
count
size
1
text
"}"
""
text.replace("}", "")
text
"{"
""
text.replace("{", "")
text
";"
""
text.replace(";", "")
fullText
text
text
end
""
print(text, end="")
findFile
True
fullText
dst.write(fullText)
lineNum
1
"\r\n-----------"
print("\r\n-----------")
"\n------\n"
dst.write("\n------\n")
findFile
False
Exception
src.close()
dst.close()
